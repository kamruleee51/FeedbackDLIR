{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58654a37",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.2\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: /home/<username>/miniconda3/envs/phd2/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: 4.7.3\n",
      "TorchVision version: 0.17.2\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.7.0\n",
      "transformers version: 4.21.3\n",
      "mlflow version: 2.11.3\n",
      "pynrrd version: 1.0.0\n",
      "clearml version: 1.15.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script for medical image analysis using MONAI and PyTorch frameworks.\n",
    "\n",
    "This script leverages the MONAI framework for healthcare imaging tasks, combined with PyTorch for model training and evaluation. \n",
    "The script demonstrates the use of data augmentation, preprocessing, and evaluation metrics for analyzing medical images. \n",
    "\n",
    "Authors:\n",
    "- Md Kamrul Hasan\n",
    "\n",
    "Date:\n",
    "- 19-Nov-2024\n",
    "\n",
    "Dependencies:\n",
    "- PyTorch\n",
    "- MONAI\n",
    "- Additional libraries as listed in the import section\n",
    "\n",
    "Note:\n",
    "Ensure all required dependencies are installed before running the script.\n",
    "\"\"\"\n",
    "\n",
    "# Import essential libraries and modules\n",
    "from monai.utils import set_determinism, first  # Utilities for reproducibility and data operations\n",
    "from monai.transforms import (  # Preprocessing and augmentation pipelines\n",
    "    EnsureChannelFirstD,\n",
    "    Compose,\n",
    "    LoadImageD,\n",
    "    RandRotateD,\n",
    "    RandZoomD,\n",
    "    ScaleIntensityRanged,\n",
    ")\n",
    "\n",
    "import monai  # MONAI library for medical image analysis\n",
    "from monai.data import DataLoader, Dataset, CacheDataset  # Data loading and caching utilities\n",
    "from monai.config import print_config, USE_COMPILED  # MONAI configuration utilities\n",
    "from monai.networks.blocks import Warp  # Spatial transformation module for medical image registration\n",
    "from monai.apps import MedNISTDataset  # Prebuilt medical datasets for quick prototyping\n",
    "\n",
    "# PyTorch imports for model creation and evaluation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable  # Automatic differentiation for operations on tensors\n",
    "import torch.nn.functional as F  # Commonly used activation functions and loss utilities\n",
    "import torch.optim as optim  # Optimizers for model training\n",
    "from torch.utils.data import DataLoader  # Data loading utility for PyTorch\n",
    "\n",
    "# Libraries for visualization and metric calculation\n",
    "import torchmetrics  # Metrics for evaluating model performance\n",
    "import matplotlib.pyplot as plt  # Visualization of results\n",
    "from torchviz import make_dot, make_dot_from_trace  # Visualize computation graphs\n",
    "from piqa import SSIM  # Structural Similarity Index Metric for image quality assessment\n",
    "import visdom  # Visualization library for tracking training progress\n",
    "\n",
    "# Additional utilities and libraries for data processing\n",
    "from glob import glob  # File searching and pattern matching\n",
    "import cv2  # Computer vision operations (e.g., image manipulation)\n",
    "from scipy.spatial.distance import directed_hausdorff  # Calculate Hausdorff distance\n",
    "import pandas as pd  # Data analysis and manipulation\n",
    "import numpy as np  # Numerical operations\n",
    "import tempfile  # Temporary file creation\n",
    "import nibabel as nib  # Neuroimaging data I/O\n",
    "import os  # Operating system interface\n",
    "\n",
    "from modules.layers import *       # Import custom layers\n",
    "from utils.helper import *         # Import helper functions\n",
    "from utils.losses import *         # Import custom loss functions\n",
    "from modules.FBA_SCA_DLIR import * # Import the FBA-SCA DLIR model implementation\n",
    "\n",
    "# MONAI-specific loss functions and metrics\n",
    "from monai.losses import *  # Predefined loss functions for medical image analysis\n",
    "from monai.metrics import *  # Evaluation metrics for medical imaging tasks\n",
    "\n",
    "# Custom configuration file\n",
    "import config  # Configuration file (ensure 'config.py' exists in the same directory)\n",
    "\n",
    "# Print MONAI configuration and set random seed for reproducibility\n",
    "print_config()  # Displays MONAI's configuration (e.g., installed version, available features)\n",
    "set_determinism(42)  # Sets the random seed for reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8094c459",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many GPUs = 2\n",
      "Selected device: cuda:1\n",
      "Device name: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GPU Availability Check and Device Setup\n",
    "\n",
    "This script checks for the availability of GPUs, sets up the appropriate device (GPU/CPU),\n",
    "and verifies the configuration to ensure efficient training.\n",
    "\"\"\"\n",
    "\n",
    "# Print the number of GPUs available\n",
    "print('How many GPUs = ' + str(torch.cuda.device_count()))\n",
    "\n",
    "# Device setup: Use GPU if available, otherwise fallback to CPU\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Selected device: {device}\")\n",
    "\n",
    "# Raise an exception if no GPU is available, as CPU training can be significantly slower\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"GPU not available. CPU training will be too slow.\")\n",
    "\n",
    "# Print the name of the GPU device being used\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeee823",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/64/\n",
      "Fixed Image Shape: torch.Size([1, 1, 64, 64, 64])\n",
      "Fixed Mask Shape: torch.Size([1, 1, 64, 64, 64])\n",
      "Moving Image Shape: torch.Size([1, 1, 64, 64, 64])\n",
      "Moving Mask Shape: torch.Size([1, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "from utils.data_loader import NiftiDataset  # Import the custom NiftiDataset class\n",
    "\n",
    "# Specify the data directory\n",
    "data_dir = 'Datasets/64/' # Replace with your actual data directory/\n",
    "print(data_dir) \n",
    "\n",
    "# Create a DataLoader for the testing dataset\n",
    "testData = DataLoader(\n",
    "    NiftiDataset(\n",
    "        sorted(glob(data_dir + \"image/*fixed.nii\")),  # Sorted list of image file paths\n",
    "        sorted(glob(data_dir + \"mask/*fixed.nii\")),   # Sorted list of mask file paths\n",
    "        transform=None  # No transformations applied to the dataset (can be customized)\n",
    "    ),\n",
    "    batch_size=1,  # Batch size for testing, defined in the config module\n",
    "    shuffle=config.shuffle_,  # Whether to shuffle the validation data\n",
    "    num_workers=config.num_workers  # Number of workers for parallel data loading\n",
    ")\n",
    "\n",
    "# Retrieve and print a sample from the testing dataset\n",
    "test_sample = first(testData)  # Get the first batch from the DataLoader\n",
    "\n",
    "# Print the shapes of the retrieved sample components\n",
    "print(\"Fixed Image Shape:\", test_sample['fixed_img'].shape)\n",
    "print(\"Fixed Mask Shape:\", test_sample['fixed_mask'].shape)\n",
    "print(\"Moving Image Shape:\", test_sample['moving_img'].shape)\n",
    "print(\"Moving Mask Shape:\", test_sample['moving_mask'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22b8a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Display Fixed and Moving Images and Masks for Validation\n",
    "\n",
    "This script visualizes the fixed and moving images as well as their respective masks from a dataset sample. \n",
    "The `imshows` function is used to render the images side by side for easy comparison.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import the imshows function from the helper module\n",
    "from utils.helper import imshows\n",
    "\n",
    "# Visualize the fixed and moving images\n",
    "imshows(test_sample['fixed_img'], test_sample['moving_img'])\n",
    "\n",
    "# Visualize the fixed and moving masks\n",
    "imshows(test_sample['fixed_mask'], test_sample['moving_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b37372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1711403380164/work/aten/src/ATen/native/TensorShape.cpp:3549.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params = 560478131\n"
     ]
    }
   ],
   "source": [
    "# Initialize evaluation metric\n",
    "# - `Dice3DMultiClass`: Computes the Dice similarity coefficient for multi-class 3D segmentation.\n",
    "# - `num_classes`: The number of classes is dynamically set based on the configuration.\n",
    "dice_multiclass_metric = Dice3DMultiClass(num_classes=config.num_classes)\n",
    "\n",
    "# Initialize custom loss functions\n",
    "# - `OptimalTransportLoss`: Implements the optimal transport loss for attention weight alignment.\n",
    "# - `twinLoss`: Computes a custom twin loss with a regularization factor (0.005 in this case).\n",
    "# - `NCCLoss`: Local normalized cross-correlation loss, commonly used for image alignment tasks.\n",
    "# - `MSELoss`: Mean Squared Error loss for regression-based tasks (default PyTorch implementation).\n",
    "# - `BendingEnergyLoss`: Regularization loss to encourage smooth deformations in image registration.\n",
    "transport_loss = OptimalTransportLoss()\n",
    "twin_loss = twinLoss(0.005)\n",
    "NCC_loss = NCCLoss()\n",
    "mse_loss = nn.MSELoss()  # Imported from PyTorch's `nn` module\n",
    "regularization_loss = BendingEnergyLoss()\n",
    "\n",
    "\n",
    "# Initialize the FBA-SCA DLIR 3D Model\n",
    "# - `FBA_SCA_DLIR3D`: Feedback Attention and Spatial-Context Alignment-based model for 3D image registration.\n",
    "# - `device`: The computation device (e.g., 'cuda' for GPU, 'cpu' for CPU) is specified dynamically based on availability.\n",
    "# - `.to(device)`: Ensures that the model is moved to the specified computation device.\n",
    "\n",
    "model = FBA_SCA_DLIR3D(device).to(device)\n",
    "\n",
    "# Initialize the Spatial Transformer module\n",
    "# - `SpatialTransformer`: Custom layer/module for applying transformations to the input volumes.\n",
    "# - This is a key component in many medical image registration frameworks, enabling the transformation of moving images to align with fixed images.\n",
    "\n",
    "spatial_transform = SpatialTransformer().to(device)\n",
    "\n",
    "# Estimate and print the total number of trainable parameters in the model\n",
    "# - `estParams`: A utility function that computes the total trainable parameters in the given model.\n",
    "# - Useful for debugging, understanding model complexity, and benchmarking.\n",
    "\n",
    "print(f'Total Params = {estParams(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7a6853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FBA_SCA_DLIR3D(\n",
       "  (coattention_encoder): encoder(\n",
       "    (conv_block1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_block2): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_block3): Sequential(\n",
       "      (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (max_pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (unet): SCARegUNet3D(\n",
       "    (encoder_block1): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(2, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (encoder_block2): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (encoder_block3): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(128, 512, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_block): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(128, 512, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (decoder_block3): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(1024, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (decoder_block2): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(512, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (decoder_block1): ResBlock_Attention(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv3d(256, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool3d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (attention_conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (final_conv): Conv3d(64, 3, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (maxpool3d): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (upsample3d): Upsample(scale_factor=2.0, mode='trilinear')\n",
       "  )\n",
       "  (barlow_twins): BarlowTwins(\n",
       "    (projector): Sequential(\n",
       "      (0): Linear(in_features=1048576, out_features=512, bias=False)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=512, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (spatial_transform): SpatialTransformer(\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (softmax): Sigmoid()\n",
       "  (prelu): ReLU(inplace=True)\n",
       "  (att_combiner): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "  (attention): SpatiotemporalAttention(\n",
       "    (exemplar_transform): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (query_transform): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (feature_gate): Conv3d(256, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name for saving the trained model's checkpoint file. \n",
    "# This name serves as an identifier for the model architecture, method, or specific experiment.\n",
    "saveFile = 'FBA_SCA_DLIR'\n",
    "\n",
    "# Path where the checkpoint of the trained model will be stored.\n",
    "# The model's parameters will be saved in this file to allow resuming training or inference later.\n",
    "# The file is saved with a `.pth` extension, commonly used in PyTorch to store model weights.\n",
    "checkpoint_path = saveFile + '.pth'\n",
    "\n",
    "# Load the model state from the checkpoint path\n",
    "# This restores the model weights from a pre-trained model for evaluation\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode, which deactivates dropout and batch normalization layers\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0802234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test NoP_detJ: 0.00039 +/- 0.00000!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script computes the fraction of non-positive Jacobian determinants (NoP_detJ) for each batch in the validation dataset \n",
    "using a deep learning model for medical image registration. \n",
    "\n",
    "The script performs the following tasks:\n",
    "1. Loops through the test dataset (`testData`) and extracts input data (images and masks).\n",
    "2. Passes the fixed and moving images through the trained model to obtain the predicted displacement field.\n",
    "3. Calculates the Jacobian determinant of the displacement field using the `jacobian_determinant` function.\n",
    "4. Computes the fraction of non-positive Jacobian determinants (NoP_detJ) for each batch.\n",
    "5. Logs the results and saves them to a CSV file.\n",
    "\n",
    "The results include the names of the test batches and the corresponding NoP_detJ values. The average and standard deviation of the \n",
    "NoP_detJ values across all test batches are printed at the end.\n",
    "\n",
    "Dependencies:\n",
    "- PyTorch\n",
    "- NumPy\n",
    "- pandas\n",
    "\n",
    "Variables:\n",
    "- `NoP_detJ_`: List storing the non-positive Jacobian determinant fractions for each test batch.\n",
    "- `Names`: List storing the names of the test batches.\n",
    "- `testData`: Validation dataset containing fixed and moving images and their respective masks.\n",
    "- `model`: The trained deep learning model used for image registration.\n",
    "- `device`: The device (CPU/GPU) where the computations are performed.\n",
    "- `saveFile`: The file path to save the results.\n",
    "\n",
    "Functions:\n",
    "- `NoP_detJ`: Computes the fraction of non-positive Jacobian determinants for a given displacement field.\n",
    "- `jacobian_determinant`: Computes the Jacobian determinant of a 3D displacement field by evaluating the spatial derivatives.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize lists to store results\n",
    "NoP_detJ_ = []  # List to store the NoP_detJ values for each test batch\n",
    "Names = []  # List to store the names of each test batch\n",
    "\n",
    "# Loop through the validation data batches\n",
    "with torch.no_grad():\n",
    "    for testBatch_data in testData:\n",
    "\n",
    "        # Extract input data for the validation batch\n",
    "        fixed_test_img = testBatch_data['fixed_img'].to(device)\n",
    "        fixed_test_msk = testBatch_data['fixed_mask'].to(device)\n",
    "        moving_test_img = testBatch_data['moving_img'].to(device)\n",
    "        moving_test_msk = testBatch_data['moving_mask'].to(device)\n",
    "\n",
    "        # Generate displacement field and predict images/masks using the trained model\n",
    "        outputs = model(fixed_test_img, moving_test_img)\n",
    "\n",
    "        # Compute the fraction of non-positive Jacobian determinants\n",
    "        NoP_detJ_.append(NoP_detJ(outputs[0]).item())\n",
    "        Names.append(testBatch_data['name'][0])  # Store the batch name\n",
    "\n",
    "    # Print the average and standard deviation of the NoP_detJ values\n",
    "    print(f\"Average test NoP_detJ: {np.mean(NoP_detJ_):.5f} +/- {np.std(NoP_detJ_):.5f}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0bbc74",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test DSC Back: 0.99549 +/- 0.00000!\n",
      "Average test DSC MYO: 0.80912 +/- 0.00000!\n",
      "Average test DSC ENDO: 0.87751 +/- 0.00000!\n",
      "Average test DSC EPI: 0.91757 +/- 0.00000!\n",
      "Average test MSE: 0.00624 +/- 0.00000!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and spatial transformer, then load pre-trained weights\n",
    "# The model is FBA_SCA_DLIR3D, which is a specific model architecture for 3D image registration\n",
    "# The spatial transformer is used to apply spatial transformations to the images\n",
    "model = FBA_SCA_DLIR3D(device).to(device)\n",
    "spatial_transform = SpatialTransformer().to(device)\n",
    "\n",
    "# Load the model state from the checkpoint path\n",
    "# This restores the model weights from a pre-trained model for evaluation\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode, which deactivates dropout and batch normalization layers\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store various evaluation metrics across the validation batches\n",
    "DSC_back, DSC_MYO, DSC_LV, DSC_EPI = [], [], [], []\n",
    "imageMatrix = []\n",
    "\n",
    "# Start the evaluation phase without tracking gradients (faster inference)\n",
    "with torch.no_grad():  # Disables gradient computation during inference for efficiency\n",
    "    # Iterate over the validation data in batches\n",
    "    for testBatch_data in testData:\n",
    "        \n",
    "        # Extract the input data (images and masks) for the validation batch\n",
    "        # These are tensors that will be moved to the device (GPU or CPU)\n",
    "        fixed_test_img = testBatch_data['fixed_img'].to(device)\n",
    "        fixed_test_msk = testBatch_data['fixed_mask'].to(device)\n",
    "        moving_test_img = testBatch_data['moving_img'].to(device)\n",
    "        moving_test_msk = testBatch_data['moving_mask'].to(device)\n",
    "\n",
    "        # Generate the displacement field and predicted images/masks by passing inputs through the model\n",
    "        output = model(fixed_test_img, moving_test_img)\n",
    "\n",
    "        # Apply spatial transformation to the predicted image to align it with the fixed image\n",
    "        pred_fixed = spatial_transform(moving_test_img, output[0]).to(device)\n",
    "\n",
    "        # Calculate the Mean Squared Error (MSE) between the predicted image and the fixed image\n",
    "        loss_raw_img1 = mse_loss(pred_fixed, fixed_test_img)\n",
    "\n",
    "        # Apply spatial transformation to the predicted mask (the model output for segmentation)\n",
    "        pred_mask_test = spatial_transform(moving_test_msk, output[0]).to(device)\n",
    "\n",
    "        # Threshold the predicted mask to convert continuous predictions into binary or categorical values\n",
    "        pred_mask_test = thresholded(pred_mask_test, config.lower_bound, config.upper_bound)\n",
    "\n",
    "        # Calculate the Dice Similarity Coefficient (DSC) for the predicted and ground truth masks\n",
    "        # DSC measures the overlap between the predicted and actual regions of interest (ROI)\n",
    "        labelDSC_test = dice_multiclass_metric(\n",
    "            make_one_hot(pred_mask_test, device, C=3),\n",
    "            make_one_hot(fixed_test_msk, device, C=3)\n",
    "        )\n",
    "\n",
    "        # Append the DSC values for each class (background, MYO, LV) to respective lists\n",
    "        DSC_back.append(labelDSC_test[0].item())\n",
    "        DSC_MYO.append(labelDSC_test[1].item())\n",
    "        DSC_LV.append(labelDSC_test[2].item())\n",
    "\n",
    "        # Store the MSE for the predicted image for later analysis\n",
    "        imageMatrix.append(loss_raw_img1.item())\n",
    "\n",
    "        # Post-process the ground truth and predicted masks to balance the classes (e.g., combine MYO and ENDO classes for EPI)\n",
    "        fixed_test_msk[fixed_test_msk == 0] = 0\n",
    "        fixed_test_msk[fixed_test_msk == 1] = 1\n",
    "        fixed_test_msk[fixed_test_msk == 2] = 1\n",
    "        pred_mask_test[pred_mask_test == 0] = 0\n",
    "        pred_mask_test[pred_mask_test == 1] = 1\n",
    "        pred_mask_test[pred_mask_test == 2] = 1\n",
    "\n",
    "        # Recalculate the DSC for the post-processed masks to ensure consistency after the balancing step\n",
    "        labelDSC_test = dice_multiclass_metric(\n",
    "            make_one_hot(pred_mask_test, device, C=3),\n",
    "            make_one_hot(fixed_test_msk, device, C=3)\n",
    "        )\n",
    "\n",
    "        # Append the DSC value for the epi layer (epicardium) to the list\n",
    "        DSC_EPI.append(labelDSC_test[1].item())\n",
    "\n",
    "    # After processing all batches, remove duplicate DSC and MSE values\n",
    "    # This ensures that the values used for metrics are unique and avoids bias from repeated values\n",
    "    DSC_back = np.unique(DSC_back)\n",
    "    DSC_MYO = np.unique(DSC_MYO)\n",
    "    DSC_LV = np.unique(DSC_LV)\n",
    "    imageMatrix = np.unique(imageMatrix)\n",
    "    DSC_EPI = np.unique(DSC_EPI)\n",
    "\n",
    "\n",
    "    # Print the average DSC and MSE for each class (background, MYO, LV, EPI)\n",
    "    # Displaying both the mean and standard deviation to provide a more complete evaluation\n",
    "    print(f\"Average test DSC Back: {np.mean(DSC_back):.5f} +/- {np.std(DSC_back):.5f}!\")\n",
    "    print(f\"Average test DSC MYO: {np.mean(DSC_MYO):.5f} +/- {np.std(DSC_MYO):.5f}!\")\n",
    "    print(f\"Average test DSC ENDO: {np.mean(DSC_LV):.5f} +/- {np.std(DSC_LV):.5f}!\")\n",
    "    print(f\"Average test DSC EPI: {np.mean(DSC_EPI):.5f} +/- {np.std(DSC_EPI):.5f}!\")\n",
    "    print(f\"Average test MSE: {np.mean(imageMatrix):.5f} +/- {np.std(imageMatrix):.5f}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f016fc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MITEA_034_scan2_\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script processes validation data for medical image registration using a trained deep learning model. \n",
    "It generates predictions for the fixed and moving images, computes masks, and saves the results as images in a specified directory.\n",
    "\n",
    "The script performs the following tasks:\n",
    "1. Checks if the specified save directory (`saveFile`) exists, and creates it if not.\n",
    "2. Loops through the batches in the validation dataset (`testData`).\n",
    "3. For each batch, extracts the fixed and moving images, as well as their corresponding masks.\n",
    "4. Reshapes the images and masks into 3D arrays (configurable size).\n",
    "5. Passes the images through the trained model to generate the displacement field and predicted images/masks.\n",
    "6. Applies spatial transformations to get the predicted fixed images and masks.\n",
    "7. Thresholds the predicted mask values and processes them for further analysis.\n",
    "8. Saves the processed images (fixed, moving, predicted images, and masks) as PNG files in the specified save directory.\n",
    "9. Outputs the name of the batch currently being processed.\n",
    "\n",
    "Dependencies:\n",
    "- PyTorch\n",
    "- NumPy\n",
    "- OpenCV (cv2)\n",
    "\n",
    "Variables:\n",
    "- `saveFile`: Path to the directory where results will be saved.\n",
    "- `testData`: Dataset containing validation batches of fixed and moving images and their corresponding masks.\n",
    "- `device`: Device (CPU/GPU) used for computations.\n",
    "- `model`: The trained deep learning model used for image registration.\n",
    "- `outputs`: Output from the model (displacement field and predicted images/masks).\n",
    "- `fixed_test_img`, `moving_test_img`: Fixed and moving images from the validation batch.\n",
    "- `fixed_test_msk`, `moving_test_msk`: Corresponding masks for the fixed and moving images.\n",
    "- `pred_disp`: The predicted displacement field generated by the model.\n",
    "- `pred_mask_test`: The predicted mask for the moving image, post thresholding.\n",
    "- `pred_img`, `pred_mask_LV_MYO`, `pred_mask_EPI`: Predicted images and masks in the 3D volume.\n",
    "- `fixed_msk_LV_MYO`, `moving_msk_LV_MYO`, `fixed_msk_EPI`, `moving_msk_EPI`: Masks reshaped and processed from the fixed and moving images.\n",
    "\n",
    "File Saving:\n",
    "- For each slice in the 3D volumes (along the z-axis), the script saves images for:\n",
    "  1. Fixed, moving, and predicted images\n",
    "  2. Fixed, moving, and predicted masks for different anatomical regions (e.g., LV_MYO, EPI)\n",
    "- The images are saved in the specified `saveFile` directory, with filenames including the batch name and slice index.\n",
    "\n",
    "The script is intended to visualize and save 3D images and masks for further evaluation or analysis.\n",
    "\n",
    "Note:\n",
    "- The script assumes that the images and masks are 3D volumes (with dimensions matching `config.img_size`).\n",
    "- The `thresholded` function is assumed to be used to binarize the mask values based on specified thresholds (`config.lower_bound` and `config.upper_bound`).\n",
    "- For debugging purposes, there are commented-out print statements and plotting functions (`PLOTs`).\n",
    "\"\"\"\n",
    "\n",
    "# Check if saveFile directory exists, if not, create it\n",
    "if not os.path.exists(saveFile):\n",
    "    os.makedirs(saveFile)\n",
    "\n",
    "# Loop through the validation data batches\n",
    "with torch.no_grad():\n",
    "    for testBatch_data in testData:\n",
    "\n",
    "        # Extract input data for the validation batch\n",
    "        fixed_test_img = testBatch_data['fixed_img'].to(device)\n",
    "        fixed_test_msk = testBatch_data['fixed_mask'].to(device)\n",
    "        moving_test_img = testBatch_data['moving_img'].to(device)\n",
    "        moving_test_msk = testBatch_data['moving_mask'].to(device)\n",
    "\n",
    "        # Reshape and detach the masks and images from the GPU\n",
    "        fixed_msk_LV_MYO = (fixed_test_msk[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "        moving_msk_LV_MYO = (moving_test_msk[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "        fixed_img = (fixed_test_img[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "        moving_img = (moving_test_img[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "\n",
    "        # Generate displacement field and predicted images/masks using the model\n",
    "        outputs = model(fixed_test_img, moving_test_img)\n",
    "\n",
    "        # Apply spatial transformation to get predicted images\n",
    "        pred_fixed = spatial_transform(moving_test_img, outputs[0]).to(device)\n",
    "        pred_img = (pred_fixed[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "\n",
    "        # Threshold and process the predicted mask\n",
    "        pred_mask_test = spatial_transform(moving_test_msk, outputs[0]).to(device)\n",
    "        pred_mask_test = thresholded(pred_mask_test, config.lower_bound, config.upper_bound)\n",
    "        pred_msk_LV_MYO = (pred_mask_test[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "\n",
    "        # Adjust masks for output consistency (binary regions for LV_MYO and EPI)\n",
    "        fixed_test_msk[fixed_test_msk == 0] = 0\n",
    "        fixed_test_msk[fixed_test_msk == 1] = 1\n",
    "        fixed_test_msk[fixed_test_msk == 2] = 1\n",
    "\n",
    "        pred_mask_test[pred_mask_test == 0] = 0\n",
    "        pred_mask_test[pred_mask_test == 1] = 1\n",
    "        pred_mask_test[pred_mask_test == 2] = 1\n",
    "\n",
    "        moving_test_msk[moving_test_msk == 0] = 0\n",
    "        moving_test_msk[moving_test_msk == 1] = 1\n",
    "        moving_test_msk[moving_test_msk == 2] = 1\n",
    "\n",
    "        # Process masks for EPI (epicardial) and LV_MYO (left ventricular myocardium)\n",
    "        fixed_msk_EPI = (fixed_test_msk[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "        pred_msk_EPI = (pred_mask_test[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "        moving_msk_EPI = (moving_test_msk[0][0]).reshape(config.img_size, config.img_size, config.img_size).detach().cpu().numpy()\n",
    "\n",
    "        # Print the name of the test batch currently being processed\n",
    "        print(testBatch_data['name'][0])\n",
    "\n",
    "        # Save the processed images and masks for each slice in the 3D volume\n",
    "        for s in range(config.img_size):\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_fixed_msk_LV_MYO_' + '{:03d}'.format(s) + '.png',\n",
    "                        100 * fixed_msk_LV_MYO[:, :, s])\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_fixed_msk_EPI_' + '{:03d}'.format(s) + '.png',\n",
    "                        100 * fixed_msk_EPI[:, :, s])\n",
    "\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_pred_msk_LV_MYO_' + '{:03d}'.format(s) + '.png',\n",
    "                        100 * pred_msk_LV_MYO[:, :, s])\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_pred_msk_EPI_' + '{:03d}'.format(s) + '.png',\n",
    "                        100 * pred_msk_EPI[:, :, s])\n",
    "\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_moving_msk_LV_MYO_' + '{:03d}'.format(s) + '.png',\n",
    "                        100 * moving_msk_LV_MYO[:, :, s])\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_moving_msk_EPI_' + '{:03d}'.format(s) + '.png',\n",
    "                        100 * moving_msk_EPI[:, :, s])\n",
    "\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_fixed_img_' + '{:03d}'.format(s) + '.png',\n",
    "                        255 * fixed_img[:, :, s])\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_moving_img_' + '{:03d}'.format(s) + '.png',\n",
    "                        255 * moving_img[:, :, s])\n",
    "            cv2.imwrite(saveFile + '/' + testBatch_data['name'][0] + '_pred_img_' + '{:03d}'.format(s) + '.png',\n",
    "                        255 * pred_img[:, :, s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b15a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
